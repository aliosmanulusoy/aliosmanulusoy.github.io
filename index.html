<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Ali Osman Ulusoy</title>
  <meta name="author" content="Ali Osman Ulusoy">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ali Osman Ulusoy</name>
              </p>
              <p>I am a software engineer at Google in Seattle where I work on <a href="https://blog.google/technology/research/project-starline/">Project Starline</a>. My background is in computer vision. 
              </p>
              <p>Before joining Google, I worked at Microsoft on <a href="https://news.microsoft.com/innovation-stories/hololens-2/">HoloLens</a> and <a href="https://azure.microsoft.com/en-us/services/spatial-anchors/">Azure Spatial Anchors</a>. I did my Phd in electrical engineering with <a href="https://en.wikipedia.org/wiki/Joseph_Mundy">Joseph Mundy</a> at <a href="www.brown.edu">Brown University</a>. After Phd, I did a post-doc at the <a href="https://ps.is.tuebingen.mpg.de/">Max-Planck Institute for Intelligent Systems</a> in Tubingen where I was advised by <a href="https://ps.is.tuebingen.mpg.de/person/black">Michael J Black</a> and <a href="https://avg.is.tuebingen.mpg.de/person/ageiger/">Andreas Geiger</a>. 
              </p>
              <p style="text-align:center">
                <a href="mailto:aliosmanulusoy@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=fkqdDEEAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp                
                <a href="https://www.linkedin.com/in/ali-osman-ulusoy-73520111/">LinkedIn</a> &nbsp/&nbsp
                <a target="_blank" rel="noopener noreferrer" href="data/cv.pdf">CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/osman2.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/osman2.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research interests span computer vision, graphics and machine learning. I'm particulary interested in inferring 3D structure and motion from images. Representative papers are <span class="highlight">highlighted</span> below.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cvpr19.png" alt="clean-usnob" width="240" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="http://www.cvlibs.net/publications/Paschalidou2019CVPR.pdf">
                <papertitle>Superquadrics Revisited: Learning 3D Shape Parsing beyond Cuboids</papertitle>
              </a>
              <br>
              <a href="https://paschalidoud.github.io/">Despoina Paschalidou</a>, <strong>Ali Osman Ulusoy</strong>, <a href="https://avg.is.tuebingen.mpg.de/person/ageiger/">Andreas Geiger</a>
              <br>
              <em>CVPR</em>, 2019
              <br>
              <a href="https://www.youtube.com/watch?v=eaZHYOsv9Lw">video</a> &nbsp/&nbsp
              <a href="https://github.com/paschalidoud/superquadric_parsing">code</a> &nbsp/&nbsp
              <a href="https://autonomousvision.github.io/superquadrics-revisited/">blog post</a>
              <p></p>
              <p>Neural networks can learn to parse a 3D model into a small set of <a href="https://en.wikipedia.org/wiki/Superquadrics">Superquadrics</a>.</p>
            </td>
          </tr>

          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cvpr18.png" alt="clean-usnob" width="240" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="http://www.cvlibs.net/publications/Paschalidou2018CVPR.pdf">
                <papertitle>RayNet: Learning Volumetric 3D Reconstruction with Ray Potentials</papertitle>
              </a>
              <br>
              <a href="https://paschalidoud.github.io/">Despoina Paschalidou</a>, <strong>Ali Osman Ulusoy</strong>, <a href="https://avg.is.tuebingen.mpg.de/person/cschmitt">Carolin Schmitt</a>, <a href="https://avg.is.tuebingen.mpg.de/person/ageiger/">Andreas Geiger</a>
              <br>
              <em>CVPR</em>, 2018 &nbsp <font color="red"><strong>(Spotlight Presentation)</strong></font>
              <br>
              <a href="https://www.youtube.com/watch?v=ebLuwu5kiGQ">video</a> &nbsp/&nbsp
              <a href="https://github.com/paschalidoud/raynet">code</a> &nbsp/&nbsp
              <a href="https://raynet-mvs.com/">project page</a> 
              <p></p>
              <p>RayNet is a neural network for 3D reconstruction from images. We integrate unrolled belief propagation within the network, so that it doesn't have to learn about geometry of perspective projection and occlusion, but rather focus on learning view-invariant features. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/3dv17.png" alt="clean-usnob" width="240" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="http://www.cvlibs.net/publications/Riegler2017THREEDV.pdf">
                <papertitle>OctNetFusion: Learning Depth Fusion from Data</papertitle>
              </a>
              <br>
              <a href="https://griegler.github.io/">Gernot Riegler</a>, <strong>Ali Osman Ulusoy</strong>, Horst Bischof, <a href="https://avg.is.tuebingen.mpg.de/person/ageiger/">Andreas Geiger</a>
              <br>
              <em>3DV</em>, 2017 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://www.youtube.com/watch?v=FiR02QygYo0">video</a> &nbsp/&nbsp
              <a href="https://github.com/griegler/octnetfusion">code</a>
              <p></p>
              <p>Learning depth-fusion can be much more accurate than traditional TSDF fusion and TV-L1 fusion. </p>
            </td>
          </tr>
          
          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cvpr17_2.png" alt="clean-usnob" width="240" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="http://www.cvlibs.net/publications/Riegler2017CVPR.pdf">
                <papertitle>OctNet: Learning Deep 3D Representations at High Resolutions</papertitle>
              </a>
              <br>
              <a href="https://griegler.github.io/">Gernot Riegler</a>, <strong>Ali Osman Ulusoy</strong>, <a href="https://avg.is.tuebingen.mpg.de/person/ageiger/">Andreas Geiger</a>
              <br>
              <em>CVPR</em>, 2017 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://www.youtube.com/watch?v=FiR02QygYo0">video</a> &nbsp/&nbsp
              <a href="https://github.com/griegler/octnet">code</a>
              <p></p>
              <p>We accelerate 3D convolutional neural networks using octrees.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cvpr17.png" alt="clean-usnob" width="240" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="http://www.cvlibs.net/publications/Ulusoy2017CVPR.pdf">
                <papertitle>Semantic Multi-view Stereo: Jointly Estimating Objects and Voxels</papertitle>
              </a>
              <br>
              <strong>Ali Osman Ulusoy</strong>, <a href="https://ps.is.tuebingen.mpg.de/person/black">Michael J Black</a>, <a href="https://avg.is.tuebingen.mpg.de/person/ageiger/">Andreas Geiger</a>
              <br>
              <em>CVPR</em>, 2017
              <br>
              <a href="https://www.youtube.com/watch?v=FiR02QygYo0">video</a>
              <p></p>
              <p>We extend our 3DV 2015 paper with object-level 3D shape priors. Inference in this factor graph yields dense 3D geometry in addition to the 6DOF pose of objects in it. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/flow.png" alt="clean-usnob" width="240" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="https://www.sciencedirect.com/science/article/abs/pii/S0262885617301014">
                <papertitle>Compression of Probabilistic Volumetric Models using multi-resolution scene flow</papertitle>
              </a>
              <br>
              Octavian Biris, <strong>Ali Osman Ulusoy</strong>, Joseph L. Mundy
              <br>
              <em> Image and Vision Computing</em>, 2017
              <br>
              <p></p>
              <p>We extend Horn and Schunck's optical flow formulation to 3D volumetric models and use it for compression.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cvpr16.png" alt="clean-usnob" width="240" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/265/UlusoyCVPR2016.pdf">
                <papertitle>Patches, Planes and Probabilities: A Non-local Prior for Volumetric 3D Reconstruction</papertitle>
              </a>
              <br>
              <strong>Ali Osman Ulusoy</strong>, <a href="https://ps.is.tuebingen.mpg.de/person/black">Michael J Black</a>, <a href="https://avg.is.tuebingen.mpg.de/person/ageiger/">Andreas Geiger</a>
              <br>
              <em>CVPR</em>, 2016
              <br>
              <a href="https://www.youtube.com/watch?v=FUYZi4jezzk&feature=emb_title">video</a> &nbsp/&nbsp
              <a href="https://github.com/aliosmanulusoy/Probabilistic-Volumetric-3D-Reconstruction">code</a>
              <p></p>
              <p>We extend our 3DV 2015 paper with non-local planarity surface priors. Much of the paper is about efficient inference in the factor graph.</p>
            </td>
          </tr>

          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/3dv2015.png" alt="clean-usnob" width="240" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/231/3DV2015.pdf">
                <papertitle>Towards Probabilistic Volumetric Reconstruction using Ray Potentials</papertitle>
              </a>
              <br>
              <strong>Ali Osman Ulusoy</strong>, <a href="https://avg.is.tuebingen.mpg.de/person/ageiger/">Andreas Geiger</a>, <a href="https://ps.is.tuebingen.mpg.de/person/black">Michael J Black</a>
              <br>
              <em>3DV</em>, 2015 &nbsp <font color="red"><strong>(Best Paper Award)</strong></font>
              <br>
              <a href="https://www.youtube.com/watch?v=NGj9sGaeOVY">video</a> &nbsp/&nbsp
              <a href="https://github.com/aliosmanulusoy/Probabilistic-Volumetric-3D-Reconstruction">code</a>
              <p></p>
              <p>We formulate multi-view stereo as inference in a factor graph. This allows exposing the inherent ambiguities in surface reconstruction from images, and incorporating surface priors. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/eccv14.gif" alt="clean-usnob" width="240" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/193/eccv14.pdf">
                <papertitle>Image-based 4-d Reconstruction Using 3-d Change Detection</papertitle>
              </a>
              <br>
              <strong>Ali Osman Ulusoy</strong>, Joseph L. Mundy
              <br>
              <em>ECCV</em>, 2014
              <br>
              <a href="https://www.youtube.com/watch?v=wrEaOC_8h-k">video</a>
              <p></p>
              <p>We use a stream of images captured over time to continuously update a 3D model with changes in the environment.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/isprs2014.png" alt="clean-usnob" width="240"height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="https://www.sciencedirect.com/science/article/abs/pii/S0924271614002354">
                <papertitle>Evaluation of feature-based 3-d registration of probabilistic volumetric scenes</papertitle>
              </a>
              <br>
              Maria Restrepo, <strong>Ali Osman Ulusoy</strong>, Joseph L. Mundy
              <br>
              <em>ISPRS Journal of Photogrammetry and Remote Sensing</em>, 2014
              <br>
              <p></p>
              <p>We study the problem of registering volumetric 3D models, by evaluating sensitivity to discretization, camera registration errors, and changes in illumination. </p>
            </td>
          </tr>

          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/iccv13.gif" alt="clean-usnob" width="240"height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/192/iccv13.pdf">
                <papertitle>Dynamic Probabilistic Volumetric Models</papertitle>
              </a>
              <br>
              <strong>Ali Osman Ulusoy</strong>, Octavian Biris, Joseph L. Mundy
              <br>
              <em>ICCV</em>, 2013
              <br>
              <a href="https://www.youtube.com/watch?v=GFs8rVeBj4k">video</a>
              <p></p>
              <p>We reconstruct arbitrary dynamic 3D scenes <i>accurately</i> using a view-dependent volumetric modeling, and <i>efficiently</i> by exploiting redundancies in space and time. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/journal.png" alt="clean-usnob" width="240"height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/191/journal.pdf">
                <papertitle>Characterization of 3-D Volumetric Probabilistic Scenes for Object Recognition</papertitle>
              </a>
              <br>
              Maria Restrepo, Brandon Mayer, <strong>Ali Osman Ulusoy</strong>, Joseph L. Mundy
              <br>
              <em>IEEE Journal of selected topics in Signal Processing</em>, 2012  
              <br>
              <p></p>
              <p>We solve 3D object recognition in the context of volumetric 3D models. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/3dimpvt2012.png" alt="clean-usnob" width="240"height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/190/3dpvt.pdf">
                <papertitle>High Resolution Surface Reconstruction from Multi-view Aerial Imagery</papertitle>
              </a>
              <br>
              Fatih Calakli, <strong>Ali Osman Ulusoy</strong>, Maria Restrepo, <a href="http://mesh.brown.edu/taubin/">Gabriel Taubin</a>, Joseph L. Mundy
              <br>
              <em>3D Imaging Modeling Processing Visualization Transmission (3DIMPVT)</em>, 2012  &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://vimeo.com/43690605">video</a>
              <p></p>
              <p>We fuse images from different viewpoints into a volumetric probabilistic model and extract a textured mesh from it.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/acva10_before.png" alt="clean-usnob" width="240"height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/188/ACVA10.pdf">
                <papertitle>Robust one-shot 3D scanning using loopy belief propagation</papertitle>
              </a>
              <br>
              <strong>Ali Osman Ulusoy</strong>, Fatih Calakli, <a href="http://mesh.brown.edu/taubin/">Gabriel Taubin</a>
              <br>
              <em>CVPR workshop</em>, 2010
              <p>We use factors graphs and belief propagation to solve 3D scanning using structured light. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/3dim09.png" alt="clean-usnob" width="240"height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/189/3dim09.pdf">
                <papertitle>One-shot scanning using de bruijn spaced grids</papertitle>
              </a>
              <br>
              <strong>Ali Osman Ulusoy</strong>, Fatih Calakli, <a href="http://mesh.brown.edu/taubin/">Gabriel Taubin</a>
              <br>
              <em>3DIM workshop at ICCV</em>, 2009
              <p>We project a grid pattern with unique spacings onto an object to reconstruct its 3D structure. </p>
            </td>
          </tr>

        </tbody></table>

      </td>
    </tr>
  </table>
</body>

</html>
